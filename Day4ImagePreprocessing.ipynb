{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNiIfeZu46JyR5COC5rDQEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaustubhhatkar/DataScience_and_MachineLearning/blob/master/Day4ImagePreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXlkrcqwAG4b",
        "outputId": "cc270b04-d4be-473b-ac2c-98a63accaa16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the blurry image\n",
        "image_path = 'blur.jpg'\n",
        "blurry_image = cv2.imread(image_path)\n",
        "\n",
        "# Step 1: Convert to grayscale\n",
        "gray_image = cv2.cvtColor(blurry_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 2: Apply Gaussian blur to reduce noise and enhance edges\n",
        "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "\n",
        "# Step 3: Thresholding to create a binary image\n",
        "_, binary_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "# Step 4: Invert the binary image (if needed)\n",
        "inverted_image = cv2.bitwise_not(binary_image)\n",
        "\n",
        "# Step 5: Apply morphological operations to further enhance text\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "processed_image = cv2.dilate(inverted_image, kernel, iterations=1)\n",
        "processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image.jpg', processed_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the blurry image\n",
        "image_path = 'blur.jpg'\n",
        "blurry_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Step 1: Apply adaptive thresholding to enhance text\n",
        "binary_image = cv2.adaptiveThreshold(blurry_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 10)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image2.jpg', binary_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40BSQfIWBLfC",
        "outputId": "2df8e1b2-45f1-4ec6-cdcd-7906a056480f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the blurry image\n",
        "image_path = 'blur.jpg'\n",
        "blurry_image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(blurry_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Increase the contrast and brightness of the text\n",
        "alpha = 1.5  # Contrast control (1.0 is no change)\n",
        "beta = 50   # Brightness control (0 is no change)\n",
        "\n",
        "enhanced_text = cv2.convertScaleAbs(gray_image, alpha=alpha, beta=beta)\n",
        "\n",
        "# Create a mask for the text to keep the background unchanged\n",
        "_, text_mask = cv2.threshold(enhanced_text, 128, 255, cv2.THRESH_BINARY)\n",
        "text_mask = cv2.cvtColor(text_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# Apply the color grading to the text (for example, make it red)\n",
        "enhanced_text_color = cv2.applyColorMap(enhanced_text, cv2.COLORMAP_JET)\n",
        "\n",
        "# Merge the enhanced text with the original background\n",
        "result_image = cv2.addWeighted(blurry_image, 1, enhanced_text_color, 0.5, 0)\n",
        "result_image = cv2.add(result_image, text_mask)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image3.jpg', result_image)\n",
        "\n",
        "# Now, you can perform OCR on the preprocessed image using your preferred OCR library (e.g., Tesseract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgDRSaWwBgti",
        "outputId": "0b471eba-9516-4c7b-9f64-6e14cbfab39f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image_path = 'blur.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Increase the brightness of the text (adjust the beta value)\n",
        "beta = 100  # You can increase this value to make the text brighter\n",
        "brighter_text = cv2.convertScaleAbs(gray_image, alpha=1.0, beta=beta)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image4.jpg', brighter_text)\n",
        "\n",
        "# Now, you can perform OCR on the preprocessed image using your preferred OCR library (e.g., Tesseract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxP5_luiCQtL",
        "outputId": "4aa6e270-42dd-4d6a-e3cb-7a9846f3bb23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "#black and white\n",
        "# Load the image\n",
        "\n",
        "image_path = 'blur2.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply adaptive histogram equalization to enhance contrast\n",
        "equalized_text = cv2.equalizeHist(gray_image)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image7.jpg', equalized_text)\n",
        "\n",
        "# Now, you can perform OCR on the preprocessed image using your preferred OCR library (e.g., Tesseract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNxPUGz2Cryw",
        "outputId": "c039df6d-2e19-4e3b-d7c4-694767b5d5eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image_path = 'blur.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply adaptive histogram equalization to enhance contrast in the entire image\n",
        "equalized_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "# Create a mask for the text (binarization)\n",
        "_, text_mask = cv2.threshold(equalized_image, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Invert the text mask to create a background mask\n",
        "background_mask = cv2.bitwise_not(text_mask)\n",
        "\n",
        "# Create a separate background image\n",
        "background_image = np.zeros_like(image)\n",
        "background_image[:] = [128, 128, 128]  # Set the background color (gray in this case)\n",
        "\n",
        "# Combine the enhanced text and background\n",
        "result_image = cv2.bitwise_and(image, image, mask=text_mask)\n",
        "result_image += cv2.bitwise_and(background_image, background_image, mask=background_mask)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image6.jpg', result_image)\n",
        "\n",
        "# Now, you can perform OCR on the preprocessed image using your preferred OCR library (e.g., Tesseract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "OZya5SYdD4xf",
        "outputId": "5134b6a9-af3d-4655-9391-2c95d1e59fd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-801736818c1e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Apply adaptive histogram equalization to enhance contrast in the entire image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the receipt image\n",
        "image_path = 'blur2.jpg'\n",
        "receipt_image = cv2.imread(image_path)\n",
        "\n",
        "# Step 1: Resize the image for consistent processing\n",
        "target_width = 1000  # Adjust the width as needed\n",
        "aspect_ratio = float(target_width) / receipt_image.shape[1]\n",
        "target_height = int(receipt_image.shape[0] * aspect_ratio)\n",
        "resized_image = cv2.resize(receipt_image, (target_width, target_height))\n",
        "\n",
        "# Step 2: Convert to grayscale\n",
        "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 3: Apply Gaussian blur to reduce noise\n",
        "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "\n",
        "# Step 4: Apply adaptive thresholding to create a binary image\n",
        "binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 10)\n",
        "\n",
        "# Step 5: Invert the binary image (if needed)\n",
        "inverted_image = cv2.bitwise_not(binary_image)\n",
        "\n",
        "# Step 6: Apply morphological operations to further enhance text\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "processed_image = cv2.dilate(inverted_image, kernel, iterations=1)\n",
        "processed_image = cv2.erode(processed_image, kernel, iterations=1)\n",
        "\n",
        "# Save the preprocessed image (optional)\n",
        "cv2.imwrite('preprocessed_image8.jpg', processed_image)\n",
        "\n",
        "# Now, you can perform OCR on the preprocessed image using your preferred OCR library (e.g., Tesseract)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "7hB_lNsEM5pg",
        "outputId": "47089882-2a33-4aed-e693-85960273de8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2cf6c7eb43e2>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 1: Resize the image for consistent processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtarget_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m  \u001b[0;31m# Adjust the width as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0maspect_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_width\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mreceipt_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtarget_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceipt_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maspect_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceipt_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}